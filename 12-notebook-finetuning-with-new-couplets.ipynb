{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I will try to finetune a small multilingual model  while using the constructed triplets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "import numpy as np\n",
    "import time\n",
    "from datasets import Dataset\n",
    "\n",
    "import sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_pandas(train_triplets.reset_index(drop=True)) # train_triplets is private\n",
    "eval_dataset = Dataset.from_pandas(valid_triplets.reset_index(drop=True))  # valid_triplets is private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('mps')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "link = \"all-MiniLM-L6-v2\"\n",
    "models = SentenceTransformer(link).to(device = device, dtype = dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer, SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "# 3. Define a loss function\n",
    "loss = MultipleNegativesRankingLoss(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/mpnet-base-all-nli-triplet\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs= 3,\n",
    "    per_device_train_batch_size = 8, #2\n",
    "    per_device_eval_batch_size= 8,  #2\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=False,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=True,  # Set to True if you have a GPU that supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    run_name=\"mpnet-base-all-nli-triplet\",  # Will be used in W&B if `wandb` is installed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SentenceTransformerTrainer(\n",
    "    model=models,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss=loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a312f11ac3f7409087311fe846e7b0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2097 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5785, 'grad_norm': 20.825035095214844, 'learning_rate': 2.380952380952381e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e900d9c904ee42659d2c62198dd11022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4362, 'grad_norm': 11.926809310913086, 'learning_rate': 4.761904761904762e-05, 'epoch': 0.29}\n",
      "{'loss': 1.567, 'grad_norm': 16.931535720825195, 'learning_rate': 4.7615262321144675e-05, 'epoch': 0.43}\n",
      "{'loss': 1.5416, 'grad_norm': 8.389205932617188, 'learning_rate': 4.49655537890832e-05, 'epoch': 0.57}\n",
      "{'loss': 1.4882, 'grad_norm': 11.200145721435547, 'learning_rate': 4.231584525702173e-05, 'epoch': 0.72}\n",
      "{'loss': 1.4042, 'grad_norm': 13.053640365600586, 'learning_rate': 3.9666136724960254e-05, 'epoch': 0.86}\n",
      "{'loss': 1.3641, 'grad_norm': 7.60820198059082, 'learning_rate': 3.701642819289878e-05, 'epoch': 1.0}\n",
      "{'loss': 1.3309, 'grad_norm': 8.626004219055176, 'learning_rate': 3.436671966083731e-05, 'epoch': 1.14}\n",
      "{'loss': 1.0378, 'grad_norm': 8.600197792053223, 'learning_rate': 3.171701112877583e-05, 'epoch': 1.28}\n",
      "{'loss': 1.0371, 'grad_norm': 14.462275505065918, 'learning_rate': 2.9067302596714363e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fde847f27a49e3ac43e319ac14a387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.009225845336914, 'eval_runtime': 3.6662, 'eval_samples_per_second': 15.002, 'eval_steps_per_second': 1.909, 'epoch': 1.43}\n",
      "{'loss': 1.0746, 'grad_norm': 7.453387260437012, 'learning_rate': 2.641759406465289e-05, 'epoch': 1.57}\n",
      "{'loss': 1.0126, 'grad_norm': 22.081600189208984, 'learning_rate': 2.3767885532591416e-05, 'epoch': 1.71}\n",
      "{'loss': 1.0417, 'grad_norm': 9.397717475891113, 'learning_rate': 2.1118177000529942e-05, 'epoch': 1.86}\n",
      "{'loss': 0.9662, 'grad_norm': 7.149302005767822, 'learning_rate': 1.846846846846847e-05, 'epoch': 2.0}\n",
      "{'loss': 0.9587, 'grad_norm': 6.786861419677734, 'learning_rate': 1.5818759936406995e-05, 'epoch': 2.14}\n",
      "{'loss': 0.6763, 'grad_norm': 11.285944938659668, 'learning_rate': 1.3169051404345523e-05, 'epoch': 2.28}\n",
      "{'loss': 0.7274, 'grad_norm': 12.25250244140625, 'learning_rate': 1.0519342872284049e-05, 'epoch': 2.42}\n",
      "{'loss': 0.7977, 'grad_norm': 14.143073081970215, 'learning_rate': 7.869634340222575e-06, 'epoch': 2.57}\n",
      "{'loss': 0.8116, 'grad_norm': 10.985814094543457, 'learning_rate': 5.2199258081611025e-06, 'epoch': 2.71}\n",
      "{'loss': 0.8912, 'grad_norm': 12.01755142211914, 'learning_rate': 2.570217276099629e-06, 'epoch': 2.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390f63b2e70747df964f908ec7cbe98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8319634795188904, 'eval_runtime': 1.5317, 'eval_samples_per_second': 35.909, 'eval_steps_per_second': 4.57, 'epoch': 2.85}\n",
      "{'train_runtime': 985.6895, 'train_samples_per_second': 17.02, 'train_steps_per_second': 2.127, 'train_loss': 1.127007174730642, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2097, training_loss=1.127007174730642, metrics={'train_runtime': 985.6895, 'train_samples_per_second': 17.02, 'train_steps_per_second': 2.127, 'total_flos': 0.0, 'train_loss': 1.127007174730642, 'epoch': 2.991416309012876})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "\n",
    "\n",
    "test_evaluator = TripletEvaluator(\n",
    "    anchors=eval_dataset[\"anchor\"],\n",
    "    positives=eval_dataset[\"positive\"],\n",
    "    negatives=eval_dataset[\"negative\"],\n",
    "    name=\"all-nli-test\",\n",
    ")\n",
    "\n",
    "test_evaluator(models)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
